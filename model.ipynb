{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:14:29.262997Z",
     "start_time": "2025-05-14T10:14:29.258146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ],
   "id": "6a129a902fb72264",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:14:30.433512Z",
     "start_time": "2025-05-14T10:14:30.429354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "9239d5cb74589449",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:38:26.848010Z",
     "start_time": "2025-05-14T13:38:26.843710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def one_hot(seqs):\n",
    "    conversion_dict={\n",
    "        'A':np.array([1.0,0.0,0.0,0.0]),\n",
    "        'C':np.array([0.0,1.0,0.0,0.0]),\n",
    "        'G':np.array([0.0,0.0,1.0,0.0]),\n",
    "        'U':np.array([0.0,0.0,0.0,1.0])\n",
    "    }\n",
    "    enc_seqs=[]\n",
    "    for seq in seqs:\n",
    "        enc_arr=conversion_dict[seq[0]]\n",
    "        for i in seq[1:]:\n",
    "            enc_arr=np.vstack((enc_arr,conversion_dict[i]))\n",
    "        #enc_arr=enc_arr.T.reshape((1,4,50))\n",
    "        enc_arr=torch.tensor(enc_arr.T, dtype = torch.float32)\n",
    "        enc_seqs.append(enc_arr)\n",
    "    enc_seqs=torch.tensor(np.array(enc_seqs),dtype = torch.float32)\n",
    "        \n",
    "    return enc_seqs\n",
    "        \n",
    "    "
   ],
   "id": "d4d4e9ce90124fa2",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:38:48.688057Z",
     "start_time": "2025-05-14T13:38:26.849674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# load data\n",
    "dataset1=pd.read_csv('data/random_train_pc.csv')\n",
    "trainseqs1=one_hot(list(dataset1[\"utr\"]))\n",
    "trainmrl1=torch.tensor(np.array(dataset1[\"rl\"]),dtype = torch.float32)\n",
    "dataset1_reshaped=list(zip(trainseqs1,trainmrl1))\n",
    "batch_size=128\n",
    "trainloader=torch.utils.data.DataLoader(dataset1_reshaped ,batch_size=batch_size,shuffle=True)\n",
    "#Daten müssen zu 2 arrays werden= sequenz und mrl\n"
   ],
   "id": "814e906b43ba192e",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:38:48.696880Z",
     "start_time": "2025-05-14T13:38:48.694128Z"
    }
   },
   "cell_type": "code",
   "source": "print(trainseqs1.shape,trainmrl1.shape)\n",
   "id": "6f1c4b333a0e7515",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([260000, 4, 50]) torch.Size([260000])\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:41:31.333566Z",
     "start_time": "2025-05-14T13:41:31.326446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(4, 120, kernel_size = 8, padding='same')\n",
    "        self.conv2 = nn.Conv1d(120, 120, kernel_size = 8, padding='same')\n",
    "        self.conv3 = nn.Conv1d(120, 120, kernel_size = 8, padding='same')\n",
    "        self.flat1 = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(6000, 40)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(40, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #print(x.shape)\n",
    "        x = self.flat1(x)\n",
    "        #x= torch.transpose(x, 1, 2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n"
   ],
   "id": "bc820dd33b03927d",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:41:35.650891Z",
     "start_time": "2025-05-14T13:41:35.641915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net=Model()\n",
    "net.to(device)"
   ],
   "id": "8d70f9b8d79e61ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv1d(4, 120, kernel_size=(8,), stride=(1,), padding=same)\n",
       "  (conv2): Conv1d(120, 120, kernel_size=(8,), stride=(1,), padding=same)\n",
       "  (conv3): Conv1d(120, 120, kernel_size=(8,), stride=(1,), padding=same)\n",
       "  (flat1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=6000, out_features=40, bias=True)\n",
       "  (drop1): Dropout(p=0.2, inplace=False)\n",
       "  (out): Linear(in_features=40, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:41:38.468172Z",
     "start_time": "2025-05-14T13:41:38.464341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.MSELoss()#(aL-y)^2\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9,0.999))#epsilon ist standradmäßig bei 1e-8\n"
   ],
   "id": "3d2ac686884690e8",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:55:51.474626Z",
     "start_time": "2025-05-14T13:55:51.469698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch():\n",
    "  net.train(True)\n",
    "\n",
    "  running_loss = 0.0\n",
    "  running_accuracy = 0.0\n",
    "\n",
    "  for batch_index, data in enumerate(trainloader):\n",
    "    inputs, correct_mrl = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "    optimizer.zero_grad()#flush gradient\n",
    "\n",
    "    outputs = net(inputs) # shape: \n",
    "    outputs = torch.reshape(outputs,(-1,))\n",
    "    #correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "    #running_accuracy += correct / batch_size\n",
    "\n",
    "    loss = criterion(outputs, correct_mrl)\n",
    "    running_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #print(batch_index)\n",
    "    if batch_index % 500 == 499:  # print every 500 batches\n",
    "      avg_loss_across_batches = running_loss / 500\n",
    "      avg_acc_across_batches = (running_accuracy / 500) * 100\n",
    "      print('Batch {0}, Loss: {1:.3f}, Accuracy: {2:.1f}%'.format(batch_index+1,\n",
    "                                                          avg_loss_across_batches,\n",
    "                                                          avg_acc_across_batches))\n",
    "      running_loss = 0.0\n",
    "      running_accuracy = 0.0\n",
    "\n",
    "    "
   ],
   "id": "eb0c82704f4b5498",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:55:27.899436Z",
     "start_time": "2025-05-14T13:55:16.709360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch_index in range(3):\n",
    "    print(f'Epoch {epoch_index+1} of 3')\n",
    "    train_one_epoch()"
   ],
   "id": "8b7fc0e1bce16b5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[84], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch_index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3\u001B[39m):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch_index\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of 3\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m     \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[79], line 19\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[0;34m()\u001B[0m\n\u001B[1;32m     17\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, correct_mrl)\n\u001B[1;32m     18\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m---> 19\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m#print(batch_index)\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    625\u001B[0m     )\n\u001B[0;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testsektion",
   "id": "1978f4d9713ebe24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:11:03.219569Z",
     "start_time": "2025-05-14T10:11:03.215996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arr=np.array([[0,1,2],\n",
    "         [3,4,5],\n",
    "         [6,7,8]])\n",
    "arr_1=arr.T\n",
    "l=[]\n",
    "l.append(arr)\n",
    "l.append(arr_1)\n",
    "print(np.array(l).shape)"
   ],
   "id": "9a334007e3f80619",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 3)\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
